# Multi-level Mixture of Experts (MMoE) for Multimodal Entity Linking

This repository contains an implementation of the **Multi-level Mixture of Experts (MMoE)** model for the **Multimodal Entity Linking (MEL)** task.  
The architecture is based on the research paper **â€œMulti-level Mixture of Experts for Multimodal Entity Linking (KDD 2025)â€**, and improves MEL performance by addressing mention ambiguity and dynamic multimodal feature selection.

---

## ğŸ” Overview

Multimodal Entity Linking aims to link a textual mention (optionally with an accompanying image) to the correct entity in a knowledge graph such as WikiData.

However, MEL is challenging due to:

1. **Mention Ambiguity** â€“ Short or unclear mention contexts create confusion.  
2. **Dynamic Selection of Modal Content** â€“ Not all tokens or image regions contribute equally.

The **MMoE model** resolves these challenges using:

- **Description-aware Mention Enhancement (DME)**  
  Enhances ambiguous mentions using WikiData descriptions chosen by an LLM (e.g., LLaMA).

- **Multimodal Feature Extraction (MFE)**  
  Uses CLIP to extract coarse- and fine-grained text & image embeddings.

- **Intra-level MoE (IntraMoE)**  
  Learns within-modality (text-only, image-only) dynamic feature importance.

- **Inter-level MoE (InterMoE)**  
  Learns cross-modal (text â†” image) interactions.

The final matching score is computed using both intra-modal and cross-modal similarity.

---

## ğŸ“¦ Dependencies

To create the environment:

```bash
conda create -n mmoe python=3.7 -y
conda activate mmoe
pip install torch==1.11.0+cu113 \
            transformers==4.27.1 \
            torchmetrics==0.11.0 \
            tokenizers==0.12.1 \
            pytorch-lightning==1.7.7 \
            omegaconf==2.2.3 \
            pillow==9.3.0

## Project Structure

MEL-MMoE/
â”‚â”€â”€ config/                 # YAML configuration files
â”‚â”€â”€ data/                   # Dataset folders
â”‚â”€â”€ codes/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ encoder.py      # CLIP-based encoder
â”‚   â”‚   â”œâ”€â”€ moe.py          # Switch-MoE
â”‚   â”‚   â”œâ”€â”€ mmoe.py         # MMoE architecture
â”‚   â”œâ”€â”€ dataset.py          # Dataset loading logic
â”‚   â”œâ”€â”€ train.py            # Training
â”‚   â”œâ”€â”€ evaluate.py         # Evaluation
â”‚   â”œâ”€â”€ predict.py          # Inference
â”‚â”€â”€ logs/                   # Training logs
â”‚â”€â”€ main.py                 # Entry point script
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
